import os
import zipfile
import gdown
from glob import glob
from PIL import Image
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from torchvision.transforms import ToTensor, Resize, InterpolationMode, PILToTensor
import pandas as pd
import csv



# ------------------------------
# Dataset Class
# ------------------------------

Questa classe definisce un custom dataset PyTorch che: legge le coppie immagine/maschera da un file CSV (annotations_file)
carica le immagini e le maschere da disco (root_dir) applica eventuali trasformazioni (transform, target_transform)- Esso verra chiamato nel train per definire train e val set:   
val_dataset = cityscapes.CityScapes(
        annotations_file=val_csv,
        root_dir=base_path,
        transform=cityscapes.transform['image'],
        target_transform=cityscapes.transform['mask']
    )


class CityScapes(Dataset):
    def __init__(self, annotations_file, root_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file)       //IL FILE CON LE COPPIE IMMAGINE LABEL
        self.root_dir = root_dir                             //DIRECTORY DOVE SI TROVA IL DATASET
        self.transform = transform                           //TRANSFORMAZIONE EVENTUALI DA APPLICARE ALL'IMMAGINE
        self.target_transform = target_transform             //TRANSFORMAZIONE EVENTUALI DA APPLICARE ALLA MASCHERA

    def __len__(self):
        return len(self.img_labels)                       //NUMERO DI ELEMENTI DEL DATASET

    def __getitem__(self, idx):                         //PRENDE LE COPPIE LE TRANSFORMA E LE RESTITUISC
        img_path = os.path.join(self.root_dir, self.img_labels.iloc[idx, 0])
        mask_path = os.path.join(self.root_dir, self.img_labels.iloc[idx, 1])

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path)

        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            mask = self.target_transform(mask)

        return image, mask

# ------------------------------
# Scarica e prepara il dataset
# ------------------------------

download_url = 'https://drive.google.com/uc?id=1Qb4UrNsjvlU-wEsR9d7rckB0YS_LXgb2'
output_zip = 'cityscapes_dataset.zip'
extract_dir = '/tmp/Cityscapes'

# ------------------------------
# Funzione per cercare cartelle ricorsivamente
# ------------------------------

//PER IL PROBLEME DI tmp/CityScape che aggiunge tutte le cartelle ogni volta
//Inutile se fatto in locale

def find_folder(start_path, folder_name):
    for root, dirs, _ in os.walk(start_path):
        if folder_name in dirs:
            return os.path.join(root, folder_name)
    return None

# ------------------------------
# Scarica ed estrai il dataset
# ------------------------------

if not os.path.exists(extract_dir) or not find_folder(extract_dir, 'images') or not find_folder(extract_dir, 'gtFine'):
    print("Dataset non trovato o incompleto, inizio il download...")
    if os.path.exists(extract_dir):
        print("Rimuovo versione incompleta...")
        os.system(f"rm -rf {extract_dir}")

    gdown.download(download_url, output_zip, quiet=False)

    print("Estrazione dell'archivio...")
    with zipfile.ZipFile(output_zip, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)

    print("Download ed estrazione completati.")
else:
    print("Dataset già presente.")

# ------------------------------
# Verifica cartelle estratte                DA TOGLIERE SE VA TUTTO OKAY
# ------------------------------


extract_dir = '/tmp/Cityscapes'
nested_path = os.path.join(extract_dir, 'Cityscapes', 'Cityscapes')
if os.path.exists(nested_path):
    extract_dir = nested_path  # entra nel livello giusto

# Rileva di nuovo le cartelle
images_dir = find_folder(extract_dir, 'images')
gtfine_dir = find_folder(extract_dir, 'gtFine')

if not images_dir or not gtfine_dir:
    raise RuntimeError("❌ Estrazione fallita: 'images' o 'gtFine' non trovati.")
else:
    print("✅ Dataset estratto correttamente.")
    print("Percorso immagini:", images_dir)
    print("Percorso maschere:", gtfine_dir)


# ------------------------------
# Trasformazioni
# ------------------------------

# VALUTARE SE EFFETTUARE ALTRE TRASFORMAZIONI
transform = {
TRASFORMAZIONI DA APPLICARE ALL'IMMAGINE
    'image': transforms.Compose([ 
        Resize((512, 1024)),                          Ridimensiona a 512x1024 pixel
         ToTensor(),                                   Converte da PIL Image a tensore [C, H, W] in float32 e normalizza tra 0 e 1
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ]),        Normalizza canali RGB con media e deviazione standard di ImageNet

//TRASFORMAZIONI DA APPLICARE ALLA MASCHERA
    'mask': transforms.Compose([
        Resize((512, 1024), interpolation=InterpolationMode.NEAREST), # 1️⃣ Ridimensiona SENZA interpolazione continua (preserva valori interi delle classi)
        PILToTensor()                                                  # 2️⃣ Converte in tensore intero [1, H, W], senza normalizzazione
    ])
}


# ------------------------------
# Crea CSV con immagini e maschere
# ------------------------------

-> ha il compito di creare un file CSV che contiene un elenco di coppie di immagini e maschere del dataset Cityscapes.

def create_cityscapes_csv(images_dir, masks_dir, output_csv, root_dir):

Usa la funzione glob per trovare tutte le immagini nel images_dir che corrispondono al pattern *_leftImg8bit.png, che sono le immagini originali del dataset Cityscapes.

    image_files = glob(os.path.join(images_dir, '*', '*_leftImg8bit.png'), recursive=True)
    data = []

    print(f"Trovate {len(image_files)} immagini.")

La funzione itera su ogni immagine trovata in image_files. basename: Ottiene il nome del file dell'immagine senza l'estensione _leftImg8bit.png.
city: Ottiene il nome della città dalla struttura delle cartelle del dataset, che è la cartella padre dell'immagine.

    for img_path in image_files:
        basename = os.path.basename(img_path).replace('_leftImg8bit.png', '')
        city = os.path.basename(os.path.dirname(img_path))

Il nome della maschera (mask_filename) viene costruito concatenando il nome dell'immagine di base con il suffisso _gtFine_labelTrainIds.png, che è il formato usato per le maschere di segmento nel dataset Cityscapes.


        mask_filename = f"{basename}_gtFine_labelTrainIds.png"
        mask_path = os.path.join(masks_dir, city, mask_filename)

SE TROVA L'ASSOCIAZIONE IMMAGINE MASCHERA LE AGGIUNGE 

        if os.path.exists(mask_path):
            # Percorsi relativi rispetto alla root del dataset
            img_rel = os.path.relpath(img_path, root_dir)
            mask_rel = os.path.relpath(mask_path, root_dir)
            data.append([img_rel, mask_rel])
        else:
            print(f"[WARNING] Maschera mancante per {img_path}") 

    if len(data) == 0:
        print("[ERROR] Nessuna coppia trovata!")

    with open(output_csv, mode='w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['image', 'mask'])            HEADER
        writer.writerows(data)                     LE SCRIVE TUTTE

    print(f"Creato CSV con {len(data)} coppie: {output_csv}")


I CSV FILE VENGONO CREATI NEL TRAIN CON
cityscapes.create_cityscapes_csv(train_images_dir, train_masks_dir, train_csv, base_path)
cityscapes.create_cityscapes_csv(val_images_dir, val_masks_dir, val_csv, base_path)

'''
