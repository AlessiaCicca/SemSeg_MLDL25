

import torch
import numpy as np
import time
from torch.utils.data import DataLoader
from models.deeplabv2.deeplabv2 import get_deeplab_v2
import datasets.cityscapes as cityscapes
from fvcore.nn import FlopCountAnalysis, flop_count_table


# MEAN INTERSECTION OVER UNION
# The Intersection over Union (IoU) metric, also referred to as the Jaccard index,
# quantifies the percent overlap between the target mask and the prediction output.

def calculate_iou(predicted_mask, target_mask):
    intersection = np.logical_and(predicted_mask, target_mask).sum()    Restituisce un array booleano con True dove entrambi i pixel sono non-zero 
                                                                         (cioè appartenenti alla classe).
    union = np.logical_or(predicted_mask, target_mask).sum()             almeno uno dei due
    iou = intersection / (union + 1e-10)                                 aggiunta errore per evitare divizione per zero
    return iou


def evaluate_model(model, outputs, masks, input_size=(224, 224), iterations=1000, device='cpu'):
    print("\n=== MODEL EVALUATION ===")
    model.eval()
    model.to(device)

    outputs_np = outputs.cpu().detach().numpy()
    masks_np = masks.cpu().detach().numpy()

NON SO A COSA SERVONO
.cpu(): Sposta il tensore dalla GPU alla CPU (se è stato originariamente elaborato sulla GPU).

.detach(): Scollega il tensore dal grafo computazionale, quindi non si calcolano i gradienti per esso.

.numpy(): Converte il tensore in un array NumPy, che è un formato compatibile con altre librerie di Python.


    iou_scores = []

Per ogni immagine nel batch: Con argmax ottieni la classe con probabilità massima per ogni pixel → maschera predetta.
Confronti con la maschera reale (target_mask) E Calcoli IoU. infine fai la media dell array con tutti i valori


    for i in range(len(outputs_np)):
        predicted_mask = np.argmax(outputs_np[i], axis=0)
        target_mask = masks_np[i, 0]
        iou = calculate_iou(predicted_mask, target_mask)
        iou_scores.append(iou)

    mean_iou = np.mean(iou_scores)
    print(f"Mean IoU: {mean_iou:.4f}")

    # Latenza & FPS   SEGUITE INDICAZIONI
    
    height, width = input_size
    image = torch.rand(1, 3, height, width).to(device)

    latency = []
    fps_list = []


     PSEUDOCODICE
    for _ in range(iterations):
        start = time.time()
        with torch.no_grad():
            _ = model(image)
        end = time.time()

        latency_i = end - start
        latency.append(latency_i)
        fps_list.append(1 / latency_i)

    mean_latency = np.mean(latency) * 1000
    std_latency = np.std(latency) * 1000
    mean_fps = np.mean(fps_list)
    std_fps = np.std(fps_list)

    print(f"Mean Latency: {mean_latency:.2f} ms")
    print(f"Std Latency: {std_latency:.2f} ms")
    print(f"Mean FPS: {mean_fps:.2f}")
    print(f"Std FPS: {std_fps:.2f}")

    # FLOPs
    image_flop = torch.zeros((1, 3, height, width)).to(device)
    flops = FlopCountAnalysis(model, image_flop)
    print(flop_count_table(flops))

    # Parametri 
    total_params = sum(p.numel() for p in model.parameters())                PARAMETRI GENERALI
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)       PARAMETRI MODIFICATI DURANTE IL TRINING
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")

p.numel() restituisce il numero totale di valori contenuti in quel parametro (ad esempio, se il parametro è una matrice 3x3, numel() restituirà 9).
torch.Tensor.requires_grad is true if gradients need to be computed for this Tensor,



QUANTO CARICO VAL DATASET NEL TRAIN CERCO DI VALUTARE SE IL MODELLO STA GENERALIZZANDO BENE
QUI MI SERVE PER TUTTE LE ALTRE METRICHE

if __name__ == "__main__":
    # ✅ Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ✅ Dataset
    val_csv = '/content/SemSeg_MLDL25/val_annotations.csv'
    base_path = '/tmp/Cityscapes/Cityscapes/Cityspaces'

    val_dataset = cityscapes.CityScapes(
        annotations_file=val_csv,
        root_dir=base_path,
        transform=cityscapes.transform['image'],
        target_transform=cityscapes.transform['mask']
    )

    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)

    # ✅ Modello
CARICA IL MODELLO
    model = get_deeplab_v2(num_classes=19).to(device)
GLI DA I PESI DEL MODELLO MIGLIORE
    model.load_state_dict(torch.load('checkpoints/best_model.pth', map_location=device))

    # ✅ Un batch per la valutazione 

IMPOSTO IL MODELLLO IN MODALITA' VALUTAZIONE: Valutazione (model.eval()): Il modello si comporta come durante la fase di inferenza o test. Il dropout è disabilitato, e le statistiche della normalizzazione del batch sono basate su dati accumulati durante l'addestramento, non su quelli del batch corrente. Questo garantisce una previsione stabile e affidabile durante l'inferenza.

    model.eval()
    with torch.no_grad():
        inputs, targets = next(iter(val_loader))    UN UNICO BATCH/ DUE IMMAGINI /CAMBIAREE
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)

    # ✅ Evaluation
    evaluate_model(model, outputs, targets, input_size=(512, 1024), iterations=100, device=device)
